{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygi5b7MfhQWa"
   },
   "source": [
    "# **SPAM CLASSIFIER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/02/17 08:50:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "#create SparkSession instance\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[5]').config('spark.driver.memory','16g').appName('sentanaly').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|label_string|                 sms|\n",
      "+------------+--------------------+\n",
      "|         ham|Go until jurong p...|\n",
      "|         ham|Ok lar... Joking ...|\n",
      "|        spam|Free entry in 2 a...|\n",
      "|         ham|U dun say so earl...|\n",
      "|         ham|Nah I don't think...|\n",
      "|        spam|FreeMsg Hey there...|\n",
      "|         ham|Even my brother i...|\n",
      "|         ham|As per your reque...|\n",
      "|        spam|WINNER!! As a val...|\n",
      "|        spam|Had your mobile 1...|\n",
      "+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data and rename column\n",
    "df = spark.read.option(\"header\", \"false\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"SMSSpamCollection.txt\") \\\n",
    "    .withColumnRenamed(\"_c0\", \"label_string\") \\\n",
    "    .withColumnRenamed(\"_c1\", \"sms\")\n",
    "\n",
    "df.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. clean data and tokenize sentences using RegexTokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"sms\", outputCol=\"tokens\", pattern=\"\\\\W+\")\n",
    "stages += [regexTokenizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CountVectorize the data\n",
    "cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"token_features\", minDF=2.0)#, vocabSize=3, minDF=2.0\n",
    "stages += [cv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Convert the labels to numerical values using binariser\n",
    "indexer = StringIndexer(inputCol=\"label_string\", outputCol=\"label\")\n",
    "stages += [indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Vectorise features using vectorassembler\n",
    "vecAssembler = VectorAssembler(inputCols=['token_features'], outputCol=\"features\")\n",
    "stages += [vecAssembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RegexTokenizer_3cec82b0c80a\n",
      "\n",
      " CountVectorizer_5b09b438d5bb\n",
      "\n",
      " StringIndexer_a4246c6045f3\n",
      "\n",
      " VectorAssembler_9901d7d71431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('\\n', stage) for stage in stages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "data = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.7, 0.3], seed = 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+-----+--------------------+\n",
      "|label_string|                 sms|              tokens|      token_features|label|            features|\n",
      "+------------+--------------------+--------------------+--------------------+-----+--------------------+\n",
      "|         ham| &lt;#&gt;  mins ...|[lt, gt, mins, bu...|(4249,[0,1,26,43,...|  0.0|(4249,[0,1,26,43,...|\n",
      "|         ham| &lt;DECIMAL&gt; ...|[lt, decimal, gt,...|(4249,[0,1,3,11,2...|  0.0|(4249,[0,1,3,11,2...|\n",
      "|         ham| and  picking the...|[and, picking, th...|(4249,[6,46,50,17...|  0.0|(4249,[6,46,50,17...|\n",
      "|         ham| came to look at ...|[came, to, look, ...|(4249,[1,4,7,8,32...|  0.0|(4249,[1,4,7,8,32...|\n",
      "|         ham| gonna let me kno...|[gonna, let, me, ...|(4249,[8,9,16,50,...|  0.0|(4249,[8,9,16,50,...|\n",
      "|         ham| said kiss, kiss,...|[said, kiss, kiss...|(4249,[0,1,3,4,8,...|  0.0|(4249,[0,1,3,4,8,...|\n",
      "|         ham| says that he's q...|[says, that, he, ...|(4249,[0,1,2,3,5,...|  0.0|(4249,[0,1,2,3,5,...|\n",
      "|         ham|\"Gimme a few\" was...|[gimme, a, few, w...|(4249,[3,43,44,65...|  0.0|(4249,[3,43,44,65...|\n",
      "|         ham|\"Happy valentines...|[happy, valentine...|(4249,[0,1,6,14,1...|  0.0|(4249,[0,1,6,14,1...|\n",
      "|         ham|\"Response\" is one...|[response, is, on...|(4249,[3,5,7,8,14...|  0.0|(4249,[3,5,7,8,14...|\n",
      "|         ham|\"SYMPTOMS\" when U...|[symptoms, when, ...|(4249,[4,5,7,13,1...|  0.0|(4249,[4,5,7,13,1...|\n",
      "|         ham|\"Speak only when ...|[speak, only, whe...|(4249,[2,4,13,22,...|  0.0|(4249,[2,4,13,22,...|\n",
      "|         ham|\"Wen u miss someo...|[wen, u, miss, so...|(4249,[1,4,5,7,8,...|  0.0|(4249,[1,4,5,7,8,...|\n",
      "|         ham|&lt;#&gt;  am I t...|[lt, gt, am, i, t...|(4249,[0,19,43,44...|  0.0|(4249,[0,19,43,44...|\n",
      "|         ham|&lt;#&gt;  is fas...|[lt, gt, is, fast...|(4249,[1,3,4,5,8,...|  0.0|(4249,[1,3,4,5,8,...|\n",
      "|         ham|&lt;#&gt;  w jett...|[lt, gt, w, jetto...|(4249,[2,35,43,44...|  0.0|(4249,[2,35,43,44...|\n",
      "|         ham|&lt;#&gt; %of ppl...|[lt, gt, of, pple...|(4249,[0,1,2,4,5,...|  0.0|(4249,[0,1,2,4,5,...|\n",
      "|         ham|&lt;#&gt; ISH MIN...|[lt, gt, ish, min...|(4249,[43,44,65,2...|  0.0|(4249,[43,44,65,2...|\n",
      "|         ham|'An Amazing Quote...|[an, amazing, quo...|(4249,[1,3,4,7,16...|  0.0|(4249,[1,3,4,7,16...|\n",
      "|         ham|'Wnevr i wana fal...|[wnevr, i, wana, ...|(4249,[0,7,9,10,2...|  0.0|(4249,[0,7,9,10,2...|\n",
      "+------------+--------------------+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "rfModel = rf.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0.0  |0.0       |[0.916473728664833,0.08352627133516687] |\n",
      "|0.0  |0.0       |[0.916473728664833,0.08352627133516687] |\n",
      "|0.0  |0.0       |[0.8552216406698138,0.14477835933018618]|\n",
      "|0.0  |0.0       |[0.8961477594764048,0.1038522405235951] |\n",
      "|0.0  |0.0       |[0.916473728664833,0.08352627133516687] |\n",
      "|0.0  |0.0       |[0.916473728664833,0.08352627133516687] |\n",
      "|0.0  |0.0       |[0.916473728664833,0.08352627133516687] |\n",
      "|0.0  |0.0       |[0.8806433524555836,0.11935664754441647]|\n",
      "|0.0  |0.0       |[0.9218105736883985,0.0781894263116016] |\n",
      "|0.0  |0.0       |[0.916473728664833,0.08352627133516687] |\n",
      "+-----+----------+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsrf = rfModel.transform(test)\n",
    "# Select results to view\n",
    "predictionsrf.limit(10).select(\"label\", \"prediction\", \"probability\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC:  0.5140845070422535\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluatorrf = BinaryClassificationEvaluator(labelCol=\"label\",rawPredictionCol=\"prediction\")\n",
    "accuracyrf = evaluatorrf.evaluate(predictionsrf)\n",
    "print (\"Test Area Under ROC: \", accuracyrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "model = nb.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------------------------------------+\n",
      "|label|prediction|probability                               |\n",
      "+-----+----------+------------------------------------------+\n",
      "|0.0  |0.0       |[0.9999996176179956,3.823820044882337E-7] |\n",
      "|0.0  |0.0       |[0.9972054995602091,0.002794500439790882] |\n",
      "|0.0  |0.0       |[0.9999999999978098,2.190326444063966E-12]|\n",
      "|0.0  |0.0       |[0.9999999999999538,4.607804951342392E-14]|\n",
      "|0.0  |0.0       |[0.999999999880886,1.1911406870203127E-10]|\n",
      "|0.0  |0.0       |[0.999688852925206,3.1114707479388615E-4] |\n",
      "|0.0  |0.0       |[0.9999999098737272,9.012627286140461E-8] |\n",
      "|0.0  |0.0       |[0.9999950690131734,4.930986826665776E-6] |\n",
      "|0.0  |0.0       |[0.9999795625725587,2.043742744135259E-5] |\n",
      "|0.0  |0.0       |[0.9999063364041348,9.366359586510845E-5] |\n",
      "+-----+----------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "# Select results to view\n",
    "predictions.limit(10).select(\"label\", \"prediction\", \"probability\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC:  0.972052252090383\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"Test Area Under ROC: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNNfZGeru6DN2lpk9MNfaPI",
   "collapsed_sections": [],
   "mount_file_id": "1eHQDd3xebM9_ZRQI7dxVKP2e6iRgLm04",
   "name": "Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
