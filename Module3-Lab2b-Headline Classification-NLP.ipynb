{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0cc588f",
   "metadata": {
    "id": "c0cc588f"
   },
   "source": [
    "#### Problem Statement: Predict the category (business, entertainment, etc.) of a news article given only its headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df8baa",
   "metadata": {
    "id": "91df8baa",
    "outputId": "4964435a-25cc-4ef9-b1a5-5406488a2c69"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749acfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[5]').config('spark.driver.memory','16g').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a2e21",
   "metadata": {
    "id": "614a2e21"
   },
   "source": [
    "Starting the Spark Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0151f",
   "metadata": {
    "id": "b4f0151f"
   },
   "source": [
    "Import Important modules required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971d950",
   "metadata": {
    "id": "a971d950"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline \n",
    "from pyspark.ml.feature import CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf,regexp_replace,isnull\n",
    "from pyspark.sql.types import StringType,IntegerType\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae8f05",
   "metadata": {
    "id": "a0ae8f05"
   },
   "source": [
    "Now we are loading the dataset uci-news-aggregator.csv.<br>\n",
    "This dataset contains headlines, URLs, and categories for 422,937 news stories collected by a web aggregator between March 10th, 2014 and August 10th, 2014.\n",
    "\n",
    "News categories included in this dataset include business; science and technology; entertainment; and health. Different news articles that refer to the same news item (e.g., several articles about recently released employment statistics) are also categorized together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec274d",
   "metadata": {
    "id": "25ec274d",
    "outputId": "217070c0-1464-44e6-9d71-3a2135379042"
   },
   "outputs": [],
   "source": [
    "#read news csv dataset from the working directory\n",
    "news_data = spark.read.csv('uci-news-aggregator.csv',header= True)\n",
    "news_data.printSchema()\n",
    "news_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a520a22",
   "metadata": {
    "id": "2a520a22"
   },
   "source": [
    "We can check the count of totalitems in the dataset for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fcc97",
   "metadata": {
    "id": "ca4fcc97",
    "outputId": "bdea19fd-348e-4fe3-d046-fb5d3d7c95f7"
   },
   "outputs": [],
   "source": [
    "#count data items present in the set\n",
    "news_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df7f9c",
   "metadata": {
    "id": "00df7f9c"
   },
   "source": [
    "We are selecting the titles of tweets and the corresponding category of each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab7451",
   "metadata": {
    "id": "7bab7451",
    "outputId": "41616eda-9f6c-4efe-b8f8-9b6748580a0f"
   },
   "outputs": [],
   "source": [
    "title_category = news_data.select(\"TITLE\",\"CATEGORY\")\n",
    "title_category.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd72e0d",
   "metadata": {
    "id": "cfd72e0d"
   },
   "source": [
    "This is the custom function definition to count the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d0cef",
   "metadata": {
    "id": "748d0cef"
   },
   "outputs": [],
   "source": [
    "#definition to count the null values\n",
    "def null_value_count(df):\n",
    "  null_columns_counts = []\n",
    "  numRows = df.count()\n",
    "  for k in df.columns:\n",
    "    nullRows = df.where(col(k).isNull()).count()\n",
    "    if(nullRows > 0):\n",
    "      temp = k,nullRows\n",
    "      null_columns_counts.append(temp)\n",
    "  return(null_columns_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa0a96",
   "metadata": {
    "id": "aeaa0a96"
   },
   "source": [
    "We are applying the custom function to the data frame title_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9d67a",
   "metadata": {
    "id": "11b9d67a"
   },
   "outputs": [],
   "source": [
    "null_columns_count_list = null_value_count(title_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ae6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns_count_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1840e9",
   "metadata": {
    "id": "3b1840e9"
   },
   "source": [
    "# Cleaning the dataset\n",
    "\n",
    "Now we can drop the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b2a42",
   "metadata": {
    "id": "534b2a42",
    "outputId": "2fb420ec-4f19-4a1b-ec68-39b85f9b0c3a"
   },
   "outputs": [],
   "source": [
    "#Drop null and not available values\n",
    "title_category = title_category.dropna()\n",
    "title_category.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_category.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf989511",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_category.select(\"Category\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1a217",
   "metadata": {
    "id": "47d1a217",
    "outputId": "9635f612-cb18-425b-e612-8839b1960563"
   },
   "outputs": [],
   "source": [
    "title_category.groupBy(\"TITLE\").count().orderBy(col(\"count\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f90f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_category.groupBy(\"Category\").count().orderBy(col(\"count\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d598390",
   "metadata": {
    "id": "0d598390"
   },
   "source": [
    "Now let us remove the numbers present in the title category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67a8cd",
   "metadata": {
    "id": "1e67a8cd",
    "outputId": "66ea4c1a-79c6-4af0-a8dd-3af1ba66b20a"
   },
   "outputs": [],
   "source": [
    "#clean numbers and other unwanted characters from the tweets\n",
    "title_category = title_category.withColumn(\"only_str\",regexp_replace(col('TITLE'), '\\d+', ''))\n",
    "title_category.select(\"TITLE\",\"only_str\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f034f",
   "metadata": {
    "id": "b49f034f"
   },
   "source": [
    "Split the text into constituent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae25af",
   "metadata": {
    "id": "1dae25af",
    "outputId": "c3c1dd8f-b68d-422f-a1b4-690ac22ad251"
   },
   "outputs": [],
   "source": [
    "#split the text to tokens using tokenizer\n",
    "#https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.RegexTokenizer.html\n",
    "regex_tokenizer = RegexTokenizer(inputCol=\"only_str\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "raw_words = regex_tokenizer.transform(title_category)\n",
    "raw_words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1526619",
   "metadata": {
    "id": "d1526619"
   },
   "source": [
    "Remove the stop words from segregated list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5434a",
   "metadata": {
    "id": "94d5434a",
    "outputId": "dcba91d6-c295-4d88-9199-da8e44db4e52"
   },
   "outputs": [],
   "source": [
    "#Remove and segregate stop words form the word list like for, by, in etc.\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "words_df = remover.transform(raw_words)\n",
    "words_df.select(\"words\",\"filtered\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7990c213",
   "metadata": {
    "id": "7990c213"
   },
   "source": [
    "The category column in the dataframe can now be mapped to categoryIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdddab39",
   "metadata": {
    "id": "bdddab39",
    "outputId": "c98ddc9d-a3c6-4143-ebba-8c0eba8aa551"
   },
   "outputs": [],
   "source": [
    "#Index the string for different category\n",
    "indexer = StringIndexer(inputCol=\"CATEGORY\", outputCol=\"categoryIndex\")\n",
    "feature_data = indexer.fit(words_df).transform(words_df)\n",
    "feature_data.select(\"CATEGORY\",\"categoryIndex\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e215cd",
   "metadata": {
    "id": "10e215cd"
   },
   "source": [
    "Convert text into vectors of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca37104",
   "metadata": {
    "id": "3ca37104"
   },
   "outputs": [],
   "source": [
    "#converting text to vectors and count the tokens\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "model = cv.fit(feature_data)\n",
    "countVectorizer_feateures = model.transform(feature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff14dc4",
   "metadata": {
    "id": "7ff14dc4"
   },
   "source": [
    "# Partition the dataset into training and test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1efd33e",
   "metadata": {
    "id": "a1efd33e",
    "outputId": "c25d68fe-2158-4831-98d6-51dfae7fd4a5"
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = countVectorizer_feateures.randomSplit([0.8, 0.2],seed = 11)\n",
    "trainingData.show()\n",
    "testData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df21afb",
   "metadata": {
    "id": "1df21afb"
   },
   "source": [
    "# Model Training and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eca5139",
   "metadata": {
    "id": "9eca5139"
   },
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e411887",
   "metadata": {
    "id": "3e411887"
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes(modelType=\"multinomial\",labelCol=\"categoryIndex\", featuresCol=\"features\")\n",
    "nbModel = nb.fit(trainingData)\n",
    "nb_predictions = nbModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e3dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0267532",
   "metadata": {
    "id": "e0267532",
    "outputId": "fb5ea116-8e47-4d5f-b73a-367b7aad872e"
   },
   "outputs": [],
   "source": [
    "nb_predictions1 = nb_predictions.select(\"prediction\", \"categoryIndex\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06720161",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c9e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "nb_accuracy = evaluator.evaluate(nb_predictions1)\n",
    "print(\"Accuracy of NB is = %g\"% (nb_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b415fcb5",
   "metadata": {
    "id": "b415fcb5"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab2_NLP_news_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
